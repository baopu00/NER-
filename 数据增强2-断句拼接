#encoding=utf8
import os,random, math

def get_length_list(filename):
    length_list = [] 
    with open(input_path+filename.replace('ann','txt'),'r',encoding = 'utf8') as f1:
        lines1 = f1.readlines()
        line1_list = lines1[0].replace('。','，').split('，')
        for line1 in line1_list[:-1]:
            length_list.append(len(line1))
        sum1 = 0
        length_sum_list = []
        for  i in length_list:
            sum1 = sum1+i+1
            length_sum_list.append(sum1)  
            
            
    return length_list,length_sum_list,line1_list[:-1]

########
#选取一个目标类别 信息放到字典中
def extrate_info(list_filename,pre): #pre 前一句子的字典长度
    random.shuffle(list_filename)

    for filename in list_filename[:1]:  #随机抽两个样本，短句进行拼接
        # 从文本中获取长度信息
        length_list,length_sum_list,line1_list = get_length_list(filename)  #打开并获取文本的断句和断句长度
        length_sum_list.insert(0,0)
    #     print(length_list,length_sum_list,line1_list)  # length_list-->length_sum_list是为短获取ind 0 1 2断句索引短，

        with open(input_path+filename,'r',encoding = 'utf8') as f2:
            lines2 = f2.readlines()
            dict_sum = {}  #一个ann文件就一个
            for ind in range(pre,len(length_sum_list)-1 + pre):
                dict_sum[ind] = []

            for line2 in lines2:  #遍历一个ann文件的每一行 ，取出每一行start和end，找到length_list列表 一个文件对应一个断句列表
                                #取出列表中最后一个长度值，进行比较，剪掉就是了注意要加1，有标点符号
                #print(line2)
                
                leibie = line2.strip().split('\t')[1].split(' ')[0]
                start= line2.strip().split('\t')[1].split(' ')[1]
                end = line2.strip().split('\t')[1].split(' ')[2]
                example = line2.strip().split('\t')[2]
                #先初始化dict_sum
            

                # 确定属于哪个短句
                def get_ind(length_sum_list,start,end,example):

                    for ind in range(len(length_sum_list)-1 + pre):
                        if eval(start) >= length_sum_list[ind] and eval(end) < length_sum_list[ind+1]:  
                            start = str(eval(start)- length_sum_list[ind])
                            end = str(eval(end)- length_sum_list[ind])
                            dict_sum[ind+pre] += [leibie+' '+start+' '+end+' '+example]
                            break
                    # return ind,start,end,example # 0 1 2
                    return dict_sum

                # ind,start,end = get_ind(length_sum_list,start,end)
                dict_sum = get_ind(length_sum_list,start,end,example)

                # dict_sum = {}  一个ann文件就一个


            return dict_sum,line1_list


def joint_func(d3,list_3,index,mask,count):
    cha = 0
    sum_list = []
    sum_list.append(0)
    num = 1
    for ii in index: #遍历选中的断句

        print(ii)
        with open(output_path+'joint'+label+'_'+str(count)+mask+'.txt','a',encoding='utf8') as f3:
#             print(list_3[ii])#########
            sum_list.append(len(list_3[ii])+1)
            if ii != index[-1]:
                f3.write(list_3[ii]+'，')
            else:
                f3.write(list_3[ii]+'。')

        with open(output_path+'joint'+label+'_'+str(count)+mask+'.ann','a',encoding='utf8') as f4:

            cha = sum(sum_list[:-1])
            for jj in d3[ii]: # ii  1 0 4 3
                 #找前一句子长度

                 #T1 T2

                leibie_ = jj.split(' ')[0]
                print(jj.split(' '))

                start_ = eval(jj.split(' ')[1])+ cha

                end_ = eval(jj.split(' ')[2]) + cha
                example_ = jj.split(' ')[3]

                f4.write('T'+ str(num)+'\t' +leibie_+' '+str(start_)+' '+str(end_)+'\t'+ example_ +'\n')
                num +=1
    return 'finish' 
input_path ='/Users/juniorfellow/Desktop/starsee/bilstm-crf-sequence-tagger/data/army_18/'
output_path ='/Users/juniorfellow/Desktop/bigram/'
label = 'Port'
n = 5

def func_11(input_path,output_path,label,n):
    #首先取标注文件
    list_filename = []
    for file in os.listdir(input_path):
        if '.ann' in file:
            with open(input_path+file,'r',encoding='utf8') as fff:
                text = fff.read()
                if text:
                    list_filename.append(file)
            #print(list_filename)

    target_list = []
    for file in os.listdir(input_path):
        if ".ann" in file:
            with open(input_path+file,'r',encoding='utf8') as ff2:
                lines22 = ff2.readlines()
                list22 = []    # 存word和标签  这里就是
                for line22 in lines22:  #原始标注 单独把所有标签取出来 为的看里面又没有port
                    list22.append(line22.strip().split('\t')[1].split(' ')[0])
                if label in list22:
                    target_list.append(file)  #target_list存所有 含有目标类别的 文件名

    for count in range(n):
        d3 = {}
        d1,list_1 = extrate_info(target_list,0)
        d2,list_2 = extrate_info(list_filename,len(d1))
        d3.update(d1)
        d3.update(d2)             #存标注汇总
        list_3 = list_1 + list_2  #存文本断句

        #开始打乱
        index_list = list(range(0,len(list_3) ))
        random.shuffle(index_list)

        mask  = 'a'
        index = index_list[:math.floor(len(list_3)/2)]

        joint_func(d3,list_3,index,mask,count)


        mask  = 'b'
        index = index_list[math.floor(len(list_3)/2):]
        joint_func(d3,list_3,index,mask,count)

    return 'finish'
    
    
func_11(input_path,output_path,label,n)




